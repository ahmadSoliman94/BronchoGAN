<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy</title>
    <meta name="description" content="The first diffusion-based video model that leverages Scene Graphs for both precise video synthesis and fine-grained human control in surgical simulation">
    <meta name="author" content="Research Team">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy">
    <meta property="og:description" content="The first diffusion-based video model that leverages Scene Graphs for both precise video synthesis and fine-grained human control">
    
    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:title" content="BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy">
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f8f9fa;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        
        /* Header */
        header {
            background: #fff;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            padding: 15px 0;
        }
        
        nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .logo {
            font-size: 1.5rem;
            font-weight: bold;
            color: #2c3e50;
        }
        
        .nav-links {
            display: flex;
            list-style: none;
            gap: 30px;
        }
        
        .nav-links a {
            text-decoration: none;
            color: #333;
            font-weight: 500;
            transition: color 0.3s;
        }
        
        .nav-links a:hover {
            color: #3498db;
        }
        
        /* Hero Section */
        .hero {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 120px 0 80px;
            text-align: center;
            margin-top: 60px;
        }
        
        .hero h1 {
            font-size: 3rem;
            margin-bottom: 20px;
            line-height: 1.2;
            max-width: 900px;
            margin-left: auto;
            margin-right: auto;
        }
        
        .hero .subtitle {
            font-size: 1.3rem;
            margin-bottom: 30px;
            opacity: 0.9;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }
        
        .authors {
            font-size: 1.1rem;
            margin-bottom: 40px;
            opacity: 0.95;
        }
        
        .authors span {
            margin: 0 5px;
        }
        
        .hero-buttons {
            display: flex;
            gap: 20px;
            justify-content: center;
            flex-wrap: wrap;
        }
        
        .btn {
            padding: 15px 30px;
            background: rgba(255,255,255,0.2);
            color: white;
            text-decoration: none;
            border-radius: 8px;
            border: 2px solid rgba(255,255,255,0.3);
            transition: all 0.3s;
            font-weight: 500;
            display: inline-flex;
            align-items: center;
            gap: 8px;
        }
        
        .btn:hover {
            background: rgba(255,255,255,0.3);
            transform: translateY(-2px);
        }
        
        .btn-primary {
            background: #3498db;
            border-color: #3498db;
        }
        
        .btn-primary:hover {
            background: #2980b9;
            border-color: #2980b9;
        }
        
        /* Sections */
        .section {
            padding: 80px 0;
            background: #fff;
        }
        
        .section:nth-child(even) {
            background: #f8f9fa;
        }
        
        .section h2 {
            font-size: 2.5rem;
            margin-bottom: 30px;
            color: #2c3e50;
            text-align: center;
        }
        
        .section-content {
            max-width: 900px;
            margin: 0 auto;
            font-size: 1.1rem;
            line-height: 1.8;
        }
        
        /* Abstract */
        .abstract {
            text-align: justify;
            font-size: 1.15rem;
            line-height: 1.8;
            background: #fff;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        
        /* Video Section */
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin: 40px 0;
        }
        
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: 10px;
        }
        
        /* Method Section */
        .method-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin-top: 40px;
        }
        
        .method-card {
            background: #fff;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            text-align: center;
        }
        
        .method-card h3 {
            color: #3498db;
            margin-bottom: 15px;
            font-size: 1.3rem;
        }
        
        /* Results Section */
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 40px;
        }
        
        .result-item {
            background: #fff;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            transition: transform 0.3s;
        }
        
        .result-item:hover {
            transform: translateY(-5px);
        }
        
        .result-item img {
            width: 100%;
            height: 200px;
            object-fit: cover;
        }
        
        .result-item .caption {
            padding: 20px;
            text-align: center;
            font-weight: 500;
        }
        
        /* Citation Box */
        .citation-box {
            background: #2c3e50;
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin: 40px 0;
        }
        
        .citation-box h3 {
            margin-bottom: 20px;
            color: #3498db;
        }
        
        .citation-box pre {
            background: rgba(255,255,255,0.1);
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.4;
        }
        
        .copy-btn {
            margin-top: 15px;
            padding: 10px 20px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background 0.3s;
        }
        
        .copy-btn:hover {
            background: #2980b9;
        }
        
        /* Footer */
        footer {
            background: #2c3e50;
            color: white;
            text-align: center;
            padding: 40px 0;
        }
        
        /* Responsive Design */
        @media (max-width: 768px) {
            .hero h1 {
                font-size: 2rem;
            }
            
            .hero .subtitle {
                font-size: 1.1rem;
            }
            
            .nav-links {
                display: none;
            }
            
            .hero-buttons {
                flex-direction: column;
                align-items: center;
            }
            
            .section h2 {
                font-size: 2rem;
            }
            
            .method-grid {
                grid-template-columns: 1fr;
            }
        }
        
        /* Smooth scrolling */
        html {
            scroll-behavior: smooth;
        }
        
        /* Placeholder for images */
        .placeholder-img {
            width: 100%;
            height: 200px;
            background: linear-gradient(45deg, #f0f0f0, #e0e0e0);
            display: flex;
            align-items: center;
            justify-content: center;
            color: #666;
            font-size: 1.1rem;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <header>
        <nav class="container">
            <div class="logo">SG2VID</div>
            <ul class="nav-links">
                <li><a href="#abstract">Abstract</a></li>
                <li><a href="#method">Method</a></li>
                <li><a href="#results">Results</a></li>
                <li><a href="#citation">Citation</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <section class="hero">
            <div class="container">
                <h1>SG2VID: Scene Graphs Enable Fine-Grained Control for Video Synthesis</h1>
                <p class="subtitle">The first diffusion-based video model that leverages Scene Graphs for both precise video synthesis and fine-grained human control in surgical simulation</p>
                <div class="authors">
                    <span>Ahmad Soliman</span>, 
                    <span>Ron Keuth</span>, 
                    <span>Marian Himstedt</span>, 
                </div>
                <div class="hero-buttons">
                    <a href="#" class="btn btn-primary">ðŸ“„ Paper</a>
                    <a href="#" class="btn">ðŸ’» Code</a>
                    <a href="#" class="btn">ðŸŽ¥ Video</a>
                    <a href="#" class="btn">ðŸ“Š Data</a>
                </div>
            </div>
        </section>

        <section id="abstract" class="section">
            <div class="container">
                <h2>Abstract</h2>
                <div class="section-content">
                    <div class="abstract">
                        Surgical simulation plays a pivotal role in training novice surgeons, accelerating their learning curve and reducing intra-operative errors. However, conventional simulation tools fall short in providing the necessary photorealism and the variability of human anatomy. In response, current methods are shifting towards generative model-based simulators. Yet, these approaches primarily focus on using increasingly complex conditioning for precise synthesis while neglecting the fine-grained human control aspect. To address this gap, we introduce SG2VID, the first diffusion-based video model that leverages Scene Graphs for both precise video synthesis and fine-grained human control. We demonstrate SG2VID's capabilities across three public datasets featuring cataract and cholecystectomy surgery. While SG2VID outperforms previous methods both qualitatively and quantitatively, it also enables precise synthesis, providing accurate control over tool and anatomy's size and movement, entrance of new tools, as well as the overall scene layout. We qualitatively motivate how SG2VID can be used for generative augmentation and present an experiment demonstrating its ability to improve a downstream phase detection task when the training set is extended with our synthetic videos. Finally, to showcase SG2VID's ability to retain human control, we interact with the Scene Graphs to generate new video samples depicting major yet rare intra-operative irregularities.
                    </div>
                </div>
            </div>
        </section>

        <section id="method" class="section">
            <div class="container">
                <h2>Method</h2>
                <div class="section-content">
                    <p>Our approach introduces a novel framework that combines scene graphs with diffusion models for controllable video synthesis in surgical contexts.</p>
                    
                    <div class="method-grid">
                        <div class="method-card">
                            <h3>Scene Graph Generation</h3>
                            <p>We develop a structured representation of surgical scenes using scene graphs that capture spatial and temporal relationships between surgical instruments and anatomical structures.</p>
                        </div>
                        <div class="method-card">
                            <h3>Diffusion-Based Synthesis</h3>
                            <p>Our diffusion model is conditioned on scene graphs to generate realistic surgical videos with fine-grained control over object positioning and movement.</p>
                        </div>
                        <div class="method-card">
                            <h3>Fine-Grained Control</h3>
                            <p>The system allows precise manipulation of surgical tool trajectories, anatomical variations, and rare intra-operative scenarios for comprehensive training.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="results" class="section">
            <div class="container">
                <h2>Results</h2>
                <div class="section-content">
                    <p>SG2VID demonstrates superior performance across multiple surgical datasets, enabling precise control over video synthesis while maintaining high visual quality.</p>
                    
                    <div class="results-grid">
                        <div class="result-item">
                            <div class="placeholder-img">Cataract Surgery Results</div>
                            <div class="caption">Cataract surgery video synthesis with controlled instrument movements</div>
                        </div>
                        <div class="result-item">
                            <div class="placeholder-img">Cholecystectomy Results</div>
                            <div class="caption">Cholecystectomy procedure generation with anatomical variations</div>
                        </div>
                        <div class="result-item">
                            <div class="placeholder-img">Quantitative Comparison</div>
                            <div class="caption">Quantitative evaluation showing improved performance metrics</div>
                        </div>
                        <div class="result-item">
                            <div class="placeholder-img">User Study</div>
                            <div class="caption">User study results demonstrating enhanced training effectiveness</div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="citation" class="section">
            <div class="container">
                <h2>Citation</h2>
                <div class="section-content">
                    <div class="citation-box">
                        <h3>BibTeX</h3>
                        <pre><code>@article{sivakumar2025sg2vid,
  title={SG2VID: Scene Graphs Enable Fine-Grained Control for Video Synthesis},
  author={Sivakumar, Ssharvien Kumar and Frisch, Yannik and Ghazaei, Ghazal and Mukhopadhyay, Anirban},
  journal={arXiv preprint arXiv:2506.03082},
  year={2025}
}</code></pre>
                        <button class="copy-btn" onclick="copyCitation()">Copy Citation</button>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Research Team. All rights reserved.</p>
        </div>
    </footer>

    <script>
        function copyCitation() {
            const citation = `@article{sivakumar2025sg2vid,
  title={SG2VID: Scene Graphs Enable Fine-Grained Control for Video Synthesis},
  author={Sivakumar, Ssharvien Kumar and Frisch, Yannik and Ghazaei, Ghazal and Mukhopadhyay, Anirban},
  journal={arXiv preprint arXiv:2506.03082},
  year={2025}
}`;
            
            navigator.clipboard.writeText(citation).then(() => {
                const btn = document.querySelector('.copy-btn');
                const originalText = btn.textContent;
                btn.textContent = 'Copied!';
                btn.style.background = '#27ae60';
                setTimeout(() => {
                    btn.textContent = originalText;
                    btn.style.background = '#3498db';
                }, 2000);
            });
        }

        // Smooth scrolling for navigation links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });
    </script>
</body>
</html>